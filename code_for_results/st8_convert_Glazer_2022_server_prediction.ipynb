{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the prediction got from CLAIRE (Glazer 2022) server for the associations of pairs formed between 10008 Zheng 2021 TCRs and 146 HLA-I alleles\n",
    "\n",
    "    build a dictionary for the pairs and their score\n",
    "    get the scores for all pairs (including duplicates)\n",
    "    reformat to matrix and save, with rows for TCRs and columns for HLAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383026\n",
      "383026\n",
      "383026\n",
      "383026\n"
     ]
    }
   ],
   "source": [
    "# Process the pairs and their scores to get scores for all pairs (including duplicates)\n",
    "# Load all pairs and scores files\n",
    "\n",
    "batch_score_folder = \"../results/st7_batch_score_folder/\"\n",
    "\n",
    "load_tcrb = []\n",
    "load_vb = []\n",
    "load_hla = []\n",
    "load_score = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    \n",
    "    df_cur_scores = pd.read_csv(batch_score_folder+\"output_\"+str(i)+\".csv\", header=0)\n",
    "    \n",
    "    load_tcrb += df_cur_scores.tcrb.tolist()\n",
    "    load_vb += df_cur_scores.vb.tolist()\n",
    "    load_hla += df_cur_scores.mhc.tolist()\n",
    "    load_score += df_cur_scores.prediction.tolist()\n",
    "    \n",
    "print(len(load_tcrb))\n",
    "print(len(load_vb))\n",
    "print(len(load_hla))\n",
    "print(len(set(list(zip(load_tcrb, load_vb, load_hla)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# whether all pairs matches between the input and output files\n",
    "file_match_flags = []\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    df_cur_pairs = pd.read_csv(\"../results/st7_batch_folder/st7_zheng_2021_hla_109_mcpas_glazer_online_unique_pairs_batch_\"+str(i)+\".csv\", header=0)\n",
    "    df_cur_scores = pd.read_csv(batch_score_folder+\"output_\"+str(i+1)+\".csv\", header=0)\n",
    "    \n",
    "    cur_tcrb_flag = (sum([x==y for x, y in zip(df_cur_pairs.tcrb.tolist(), df_cur_scores.tcrb.tolist())]) == df_cur_pairs.shape[0])\n",
    "    cur_vb_flag = (sum([x==y for x, y in zip(df_cur_pairs.vb.tolist(), df_cur_scores.vb.tolist())]) == df_cur_pairs.shape[0])   \n",
    "    cur_hla_flag = (sum([x==y for x, y in zip(df_cur_pairs.mhc.tolist(), df_cur_scores.mhc.tolist())]) == df_cur_pairs.shape[0])\n",
    "    \n",
    "    cur_flag = ((cur_tcrb_flag and cur_vb_flag) and cur_hla_flag)\n",
    "    \n",
    "    file_match_flags += [cur_flag]\n",
    "    \n",
    "print(file_match_flags)\n",
    "\n",
    "# double check whether all pairs matches those in the original unique pair file\n",
    "\n",
    "csv_unique_pairs = pd.read_csv(\"../results/st7_zheng_2021_hla_109_mcpas_glazer_online_unique_pairs.csv\", header=0)\n",
    "print(sum([x==y for x,y in zip(csv_unique_pairs.tcrb.tolist(), load_tcrb)])/csv_unique_pairs.shape[0])\n",
    "print(sum([x==y for x,y in zip(csv_unique_pairs.vb.tolist(), load_vb)])/csv_unique_pairs.shape[0])\n",
    "print(sum([x==y for x,y in zip(csv_unique_pairs.mhc.tolist(), load_hla)])/csv_unique_pairs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383026\n",
      "0.9948988556861876\n",
      "0.0046807117760181\n"
     ]
    }
   ],
   "source": [
    "# build a dictionary for the pairs and their corresponding scores\n",
    "\n",
    "score_dict = defaultdict(float)\n",
    "\n",
    "for tcrb, vb, hla, score in zip(load_tcrb, load_vb, load_hla, load_score):\n",
    "    score_dict[(tcrb, vb, hla)] = score\n",
    "    \n",
    "print(len(score_dict))\n",
    "print(max(score_dict.values()))\n",
    "print(min(score_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1090872, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pairs with duplicates, in order to get scores for all pairs\n",
    "csv_pos = pd.read_csv(\"../results/st7_zheng_2021_hla_109_mcpas_glazer_online.csv\", header=0)\n",
    "csv_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcrb_w_dup = csv_pos.tcrb.tolist()\n",
    "vb_w_dup = csv_pos.vb.tolist()\n",
    "mhc_w_dup = csv_pos.mhc.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_columns = mhc_w_dup[:109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1090872, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1090872"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_w_dup = [score_dict[(tcrb, vb, hla)] for tcrb, vb, hla in zip(tcrb_w_dup, vb_w_dup, mhc_w_dup)]\n",
    "\n",
    "print(csv_pos.shape)\n",
    "len(scores_w_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383026"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10008.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = np.array(scores_w_dup)\n",
    "\n",
    "len(tcrb_w_dup)/109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51867741, 0.92720938, 0.40561506, 0.87267429, 0.8846783 ,\n",
       "        0.84183466],\n",
       "       [0.51867741, 0.92720938, 0.40561506, 0.87267429, 0.8846783 ,\n",
       "        0.84183466]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_reshape = yhat.reshape(int(len(tcrb_w_dup)/109), len(raw_columns))\n",
    "\n",
    "yhat_reshape[:2, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5186774134635925,\n",
       " 0.9272093772888184,\n",
       " 0.4056150615215301,\n",
       " 0.872674286365509,\n",
       " 0.884678304195404,\n",
       " 0.8418346643447876]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_w_dup[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5186774134635925,\n",
       " 0.9272093772888184,\n",
       " 0.4056150615215301,\n",
       " 0.872674286365509,\n",
       " 0.884678304195404,\n",
       " 0.8418346643447876]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_w_dup[109:(109+6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_columns = [x[:5] + \"*\" + x[5:] for x in raw_columns]\n",
    "\n",
    "df_scores = pd.DataFrame(yhat_reshape, columns=star_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend for all 146 HLAs following the format for DePTH, \n",
    "# for the convenience of later processing\n",
    "\n",
    "convert_filename = \"st7_hla_chowell_146_mcpas_convert_39.csv\"\n",
    "df_convert = pd.read_csv(\"../results/\"+convert_filename, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hla_chowell_146</th>\n",
       "      <th>hla_convert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0101</td>\n",
       "      <td>HLA-A01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0102</td>\n",
       "      <td>HLA-A01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0103</td>\n",
       "      <td>HLA-A01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0201</td>\n",
       "      <td>HLA-A02:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0202</td>\n",
       "      <td>HLA-A02:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0203</td>\n",
       "      <td>HLA-A02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0205</td>\n",
       "      <td>HLA-A02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0206</td>\n",
       "      <td>HLA-A02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0207</td>\n",
       "      <td>HLA-A02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0217</td>\n",
       "      <td>HLA-A02:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hla_chowell_146 hla_convert\n",
       "0           A0101  HLA-A01:01\n",
       "1           A0102  HLA-A01:01\n",
       "2           A0103  HLA-A01:01\n",
       "3           A0201  HLA-A02:01\n",
       "4           A0202  HLA-A02:02\n",
       "5           A0203  HLA-A02:03\n",
       "6           A0205  HLA-A02:05\n",
       "7           A0206  HLA-A02:06\n",
       "8           A0207  HLA-A02:07\n",
       "9           A0217  HLA-A02:17"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_convert[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_extend = defaultdict(list)\n",
    "\n",
    "for chowell, claire in zip(df_convert.hla_chowell_146.tolist(), \n",
    "                           df_convert.hla_convert.tolist()):\n",
    "    claire_star = claire[:5] + \"*\" + claire[5:]\n",
    "    dict_extend[chowell] = df_scores[claire_star].tolist()\n",
    "\n",
    "    \n",
    "len(dict_extend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extend = pd.DataFrame.from_dict(dict_extend)\n",
    "\n",
    "df_extend.to_csv(\"../results/st8_Glazer_2022_server_on_zheng_2021_pos_extended_hlas_146.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10008, 146)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
