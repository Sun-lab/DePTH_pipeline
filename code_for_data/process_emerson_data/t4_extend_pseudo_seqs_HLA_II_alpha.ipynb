{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file extends the pseudo sequences for HLA I alleles\n",
    "\n",
    "One tricky part in this file is on the adjustments needed for verifying the alignments. A summary on the final findings in order to reconstruct the old and construct the extended pseudo sequences is put in file\n",
    "\n",
    "    t4_summary.md\n",
    "\n",
    "We have pseudo sequences for HLA alleles on 15 positions for HLA-II alpha chains contained in file \n",
    "\n",
    "    ../../data/intermediate_data/pseudosequence_2016_all_X.dat\n",
    "\n",
    "We want to extend the positions to also cover those additional positions got from \n",
    "\n",
    "    t2_check_additional_pos_contacts.log.ipynb.\n",
    "\n",
    "First, we need to check whether we can get an unique pseudo sequence for each HLA on the additional positions.\n",
    "\n",
    "If that is true, secondly, we will keep those positions with diversity in amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Materials:\n",
    "\n",
    "Full sequence files: \n",
    "\n",
    "    ../../data/intermediate_data/HLA_TCR_contact/DRA_prot.alfas\n",
    "\n",
    "    ../../data/intermediate_data/HLA_TCR_contact/DPA_prot.alfas\n",
    "\n",
    "    ../../data/intermediate_data/HLA_TCR_contact/DQA_prot.alfas\n",
    "\n",
    "The 15 positions (needs other additional adjustment. the adjustment needs to follow the findings summarized in step70_summary.txt) for HLA-II alleles from NetMHCIIpan-3.0:\n",
    "\n",
    "9, 11, 22, 24, 31, 52, 53, 58, 59, 61, 65, 66, 68, 72, 73\n",
    "\n",
    "18 additional positions (0-indexed) from t2_check_additional_pos_contacts.log.ipynb:\n",
    "\n",
    "4, 28, 35, 39, 45, 46, 47, 50, 51, 53, 56, 58, 60, 63, 65, 67, 71, 72\n",
    "\n",
    "pseudo sequences for HLA alleles on 15 positions for HLA-II alpha chains contained in file\n",
    "\n",
    "    ../../data/intermediate_data/pseudosequence_2016_all_X.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HLA</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DRB1_0101</td>\n",
       "      <td>QEFFIASGAAVDAIMWLFLECYDLQRATYHVGFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRB1_0102</td>\n",
       "      <td>QEFFIASGAAVDAIMWLFLECYDLQRATYHAVFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRB1_0103</td>\n",
       "      <td>QEFFIASGAAVDAIMWLFLECYDIDEATYHVGFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DRB1_0104</td>\n",
       "      <td>QEFFIASGAAVDAIMWLFLECYDLQRANYHVVFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DRB1_0105</td>\n",
       "      <td>QEFFIASGAAVDAIMWLFLECYDLQRATYHVGFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DRB1_0106</td>\n",
       "      <td>QEFFIASGAAVDAIMWLFLECYDLQAATYHVVFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HLA                                 seq\n",
       "0  DRB1_0101  QEFFIASGAAVDAIMWLFLECYDLQRATYHVGFT\n",
       "1  DRB1_0102  QEFFIASGAAVDAIMWLFLECYDLQRATYHAVFT\n",
       "2  DRB1_0103  QEFFIASGAAVDAIMWLFLECYDIDEATYHVGFT\n",
       "3  DRB1_0104  QEFFIASGAAVDAIMWLFLECYDLQRANYHVVFT\n",
       "4  DRB1_0105  QEFFIASGAAVDAIMWLFLECYDLQRATYHVGFT\n",
       "5  DRB1_0106  QEFFIASGAAVDAIMWLFLECYDLQAATYHVVFT"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLA_2_pseudo = pd.read_csv(\"../../data/intermediate_data/pseudosequence_2016_all_X.dat\", sep = \"\\t\", header = None)\n",
    "HLA_2_pseudo.shape\n",
    "# (5636, 2)\n",
    "HLA_2_pseudo.columns = [\"HLA\", \"seq\"]\n",
    "HLA_2_pseudo[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5635"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build pseudo sequence dictionary\n",
    "\n",
    "# from the exploration in t3_explore_II.ipynb, \n",
    "# the only HLA-II pair with two corresponding rows in this table is 'HLA-DPA10103-DPB10601'\n",
    "# this one is not among the HLA-II pairs that we consider as in HLA v2 table from DeWitt_2018\n",
    "# so ignore this issue for now and just assign the later pseudo seq to it\n",
    "\n",
    "HLA_2_pseudo_dict = defaultdict(str)\n",
    "\n",
    "for hla, seq in zip(HLA_2_pseudo.HLA.tolist(), HLA_2_pseudo.seq.tolist()):\n",
    "    HLA_2_pseudo_dict[hla] = seq[:15]\n",
    "\n",
    "len(HLA_2_pseudo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the original 15 positions from NetMHC-II-pan-3.0 paper\n",
    "fifteen = [9, 11, 22, 24, 31, 52, 53, 58, 59, 61, 65, 66, 68, 72, 73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>hla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature:</td>\n",
       "      <td>HLA-DPAB*02:01_04:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature:</td>\n",
       "      <td>HLA-DQAB*05:05_06:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature:</td>\n",
       "      <td>HLA-B*08:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature:</td>\n",
       "      <td>HLA-A*24:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feature:</td>\n",
       "      <td>HLA-A*24:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feature:</td>\n",
       "      <td>HLA-B*38:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature                   hla\n",
       "0  feature:  HLA-DPAB*02:01_04:01\n",
       "1  feature:  HLA-DQAB*05:05_06:04\n",
       "2  feature:           HLA-B*08:01\n",
       "3  feature:           HLA-A*24:02\n",
       "4  feature:           HLA-A*24:03\n",
       "5  feature:           HLA-B*38:02"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get HLA-II pair names from HLA_v2_features\n",
    "HLA_v2_features_row_names = pd.read_csv(\"../../data/intermediate_data/DeWitt_2018/HLA_v2_features_row_names.txt\", \n",
    "                                        sep = \" \", header = None)\n",
    "HLA_v2_features_row_names.columns = [\"feature\", \"hla\"]\n",
    "HLA_v2_features_row_names.shape\n",
    "# (215, 2)\n",
    "HLA_v2_features_row_names[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_II_v2_pairs = [hla for hla in HLA_v2_features_row_names.hla.tolist() if hla[:7] in [\"HLA-DPA\", \"HLA-DQA\", \"HLA-DRD\", \"HLA-DRB\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HLA-DRDQ*10:01_01:05_05:01',\n",
       " 'HLA-DRDQ*03:01_05:01_02:01',\n",
       " 'HLA-DRDQ*13:01_01:03_06:03',\n",
       " 'HLA-DRDQ*15:01_01:02_06:02',\n",
       " 'HLA-DRDQ*09:01_03:02_03:03']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLA_II_v2_5DRDQ = [item for item in HLA_II_v2_pairs if len(item.split(\"_\")) > 2]\n",
    "HLA_II_v2_5DRDQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HLA-DQAB*01:05_05:01',\n",
       " 'HLA-DQAB*05:01_02:01',\n",
       " 'HLA-DQAB*01:03_06:03',\n",
       " 'HLA-DQAB*01:02_06:02',\n",
       " 'HLA-DQAB*03:02_03:03']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLA_II_v2_5DRDQ_DRB = [\"HLA-DRB1*\" + item[9:].split(\"_\")[0] for item in HLA_II_v2_5DRDQ]\n",
    "HLA_II_v2_5DRDQ_DQAB = [\"HLA-DQAB*\" + \"_\".join(item[9:].split(\"_\")[1:]) for item in HLA_II_v2_5DRDQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HLA-DRB1*16:01',\n",
       " 'HLA-DRB1*11:02',\n",
       " 'HLA-DQAB*01:02_03:02',\n",
       " 'HLA-DRB1*13:01',\n",
       " 'HLA-DRB1*03:01',\n",
       " 'HLA-DRB1*11:04']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLA_II_complete = list(set(HLA_II_v2_pairs + HLA_II_v2_5DRDQ_DRB + HLA_II_v2_5DRDQ_DQAB) - set(HLA_II_v2_5DRDQ))\n",
    "len(HLA_II_complete)\n",
    "# 135\n",
    "HLA_II_complete[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct pseudo sequences on the 15 positions of alpha chain\n",
    "\n",
    "# map each HLA-II pair to the corresponding alpha chain\n",
    "# load the corresponding pseudo sequeneces and get the first 15\n",
    "# reconstruct the pseudo sequences based on position adjustments\n",
    "#  -- load the three full sequences files\n",
    "#  -- the lists of DQAs with deletion\n",
    "#  -- write functions to reconstruct pseudo sequences\n",
    "# check whether for each HLA-II alpha chain, the pseudo sequences on the 18 additional positions\n",
    "#  are the same too\n",
    "# if so, move on and write out a file of the alpha chain names and their corresponding pseudo \n",
    "#  sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HLA_II_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this first dictionary holds the corresponding alpha chain of each HLA-II pair\n",
    "HLA_II_alpha_dict = defaultdict(str)\n",
    "# this second dictionary holds the translate of one HLA-II pair to the names in \"../../data/intermediate_data/pseudosequence_2016_all_X.dat\"\n",
    "trans_hla_II_dict = defaultdict(str)\n",
    "# based on the existing pseudo sequence dictionary, build one for alpha chain and possible\n",
    "# corresponding set of pseudo sequences -- expected to be set of len 1 if no bug\n",
    "HLA_II_alpha_set_pseudo_dict = defaultdict(set)\n",
    "\n",
    "# separate the HLA-II pairs into two alleles each\n",
    "# translate them into the names in file \"../../data/intermediate_data/pseudosequence_2016_all_X.dat\"\n",
    "for item in HLA_II_complete:\n",
    "    if item[:8] == \"HLA-DQAB\":\n",
    "        item_1 = \"DQA1\" + \"*\" + item[9:].split(\"_\")[0]\n",
    "        item_2 = \"DQB1\" + \"*\" + item[9:].split(\"_\")[1]\n",
    "        HLA_II_alpha_dict[item] = item_1\n",
    "        trans_hla_II_dict[item] = \"HLA-\" + item_1.replace(\"*\", \"\").replace(\":\", \"\") + \"-\" + item_2.replace(\"*\", \"\").replace(\":\", \"\")\n",
    "        HLA_II_alpha_set_pseudo_dict[item_1].add(HLA_2_pseudo_dict[trans_hla_II_dict[item]][:15])\n",
    "    elif item[:8] == \"HLA-DPAB\":\n",
    "        item_1 = \"DPA1\" + \"*\" + item[9:].split(\"_\")[0]\n",
    "        item_2 = \"DPB1\" + \"*\" + item[9:].split(\"_\")[1]\n",
    "        HLA_II_alpha_dict[item] = item_1\n",
    "        trans_hla_II_dict[item] = \"HLA-\" + item_1.replace(\"*\", \"\").replace(\":\", \"\") + \"-\" + item_2.replace(\"*\", \"\").replace(\":\", \"\")\n",
    "        HLA_II_alpha_set_pseudo_dict[item_1].add(HLA_2_pseudo_dict[trans_hla_II_dict[item]][:15])\n",
    "    elif item[:8] == \"HLA-DRB1\":\n",
    "        item_1 = \"DRA\"\n",
    "        item_2 = \"DRB1\" + \"*\" + item[9:]\n",
    "        HLA_II_alpha_dict[item] = item_1\n",
    "        trans_hla_II_dict[item] = 'DRB1_' + item[9:].replace(\":\", \"\")\n",
    "        HLA_II_alpha_set_pseudo_dict[item_1].add(HLA_2_pseudo_dict[trans_hla_II_dict[item]][:15])\n",
    "    else:\n",
    "        print(\"error found, first eight letters exception\")\n",
    "        print(item)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DPA1*01:03',\n",
       " 'DPA1*02:01',\n",
       " 'DPA1*02:02',\n",
       " 'DQA1*01:01',\n",
       " 'DQA1*01:02',\n",
       " 'DQA1*01:03',\n",
       " 'DQA1*01:04',\n",
       " 'DQA1*01:05',\n",
       " 'DQA1*02:01',\n",
       " 'DQA1*03:01',\n",
       " 'DQA1*03:02',\n",
       " 'DQA1*03:03',\n",
       " 'DQA1*04:01',\n",
       " 'DQA1*05:01',\n",
       " 'DQA1*05:05',\n",
       " 'DQA1*06:01',\n",
       " 'DRA']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(HLA_II_alpha_dict.values())\n",
    "list_HLA_II_alpha = list(set(HLA_II_alpha_dict.values()))\n",
    "list_HLA_II_alpha.sort()\n",
    "list_HLA_II_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(value) for value in HLA_II_alpha_set_pseudo_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use HLA_II_alpha_set_pseudo_dict to get a dict with pseudo seq as value\n",
    "HLA_II_alpha_pseudo_dict = defaultdict(str)\n",
    "\n",
    "for key in HLA_II_alpha_set_pseudo_dict:\n",
    "    HLA_II_alpha_pseudo_dict[key] = list(HLA_II_alpha_set_pseudo_dict[key])[0]\n",
    "\n",
    "len(HLA_II_alpha_pseudo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are the adjustments need to make in order to reconstruct the pseudo sequence on \n",
    "# original 15 positions:\n",
    "# (0) DPA, DQA are processed by subtracting 4 from the indexes from pos_alpha, \n",
    "#        with the first aa replaced by the one before it;\n",
    "# (1) If DQA falls into the list extra_modify_DQAs, need to modify positions \n",
    "#        52 & 53 (1-indexed under NetMHC_II_pan-3.0);\n",
    "# (2) Get rid of those starting with 'X', if there are multiple pseudo seq candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full sequences files\n",
    "\n",
    "Load DRA sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HVIIQ-AEFYLNPDQSGEFMFDFDGDEIFHVDMAKKETVWRLEEFGRFASFEAQGALANIAVDKANLEIMTKRSN'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DRA_prot = pd.read_csv(\"../../data/intermediate_data/HLA_TCR_contact/DRA_prot.alfas\", \n",
    "                       sep = \" \", header = None)\n",
    "DRA_prot.shape\n",
    "\n",
    "name_ind = list(range(int(DRA_prot.shape[0]/2)))\n",
    "names = DRA_prot.loc[[2 * ind for ind in name_ind]]\n",
    "names = names.iloc[:, 0].tolist()\n",
    "names = [name.replace(\">\", \"\") for name in names]\n",
    "seqs = DRA_prot.loc[[2 * ind + 1 for ind in name_ind]]\n",
    "seqs = seqs.iloc[:, 0].tolist()\n",
    "\n",
    "DRA_seqs = pd.DataFrame(list(zip(names, seqs)), \n",
    "                            columns =['name', 'seq']) \n",
    "DRA_seqs.shape\n",
    "\n",
    "DRA_seq_unique = list(set(DRA_seqs.seq.tolist()))[0]\n",
    "DRA_seq_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DPA sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DPA1_prot = pd.read_csv(\"../../data/intermediate_data/HLA_TCR_contact/DPA1_prot.alfas\", \n",
    "                        sep = \" \", header = None)\n",
    "DPA1_prot.shape\n",
    "\n",
    "name_ind = list(range(int(DPA1_prot.shape[0]/2)))\n",
    "names = DPA1_prot.loc[[2 * ind for ind in name_ind]]\n",
    "names = names.iloc[:, 0].tolist()\n",
    "names = [name.replace(\">\", \"\") for name in names]\n",
    "seqs = DPA1_prot.loc[[2 * ind + 1 for ind in name_ind]]\n",
    "seqs = seqs.iloc[:, 0].tolist()\n",
    "\n",
    "DPA1_seqs = pd.DataFrame(list(zip(names, seqs)), \n",
    "                            columns =['name', 'seq']) \n",
    "DPA1_seqs.shape\n",
    "\n",
    "DPA1_seqs['short'] = [\":\".join(name.split(\":\")[:2]) for name in DPA1_seqs.name.tolist()]\n",
    "DPA1_seq_dict = defaultdict(set)\n",
    "for short, seq in zip(DPA1_seqs.short.tolist(), DPA1_seqs.seq.tolist()):\n",
    "    DPA1_seq_dict[short].add(seq)\n",
    "\n",
    "len(DPA1_seq_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DQA sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DQA1_prot = pd.read_csv(\"../../data/intermediate_data/HLA_TCR_contact/DQA1_prot.alfas\", \n",
    "                        sep = \" \", header = None)\n",
    "DQA1_prot.shape\n",
    "\n",
    "name_ind = list(range(int(DQA1_prot.shape[0]/2)))\n",
    "names = DQA1_prot.loc[[2 * ind for ind in name_ind]]\n",
    "names = names.iloc[:, 0].tolist()\n",
    "names = [name.replace(\">\", \"\") for name in names]\n",
    "seqs = DQA1_prot.loc[[2 * ind + 1 for ind in name_ind]]\n",
    "seqs = seqs.iloc[:, 0].tolist()\n",
    "\n",
    "DQA1_seqs = pd.DataFrame(list(zip(names, seqs)), \n",
    "                            columns =['name', 'seq']) \n",
    "DQA1_seqs.shape\n",
    "\n",
    "DQA1_seqs['short'] = [\":\".join(name.split(\":\")[:2]) for name in DQA1_seqs.name.tolist()]\n",
    "\n",
    "DQA1_seq_dict = defaultdict(set)\n",
    "for short, seq in zip(DQA1_seqs.short.tolist(), DQA1_seqs.seq.tolist()):\n",
    "    DQA1_seq_dict[short].add(seq)\n",
    "\n",
    "len(DQA1_seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DLGRKETVWCLPV-LRQFRFDPQFALTNIAVLKHNLNSLIKRSN'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(DQA1_seq_dict['DQA1*05:04'])[0][31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of DQAs that need additional modifications\n",
    "extra_modify_DQAs = ['DQA1*05:04', 'DQA1*05:07', 'DQA1*05:01', 'DQA1*05:06', 'DQA1*05:03', \\\n",
    "                    'DQA1*05:02', 'DQA1*05:08', 'DQA1*05:05', 'DQA1*05:11', 'DQA1*05:10', \\\n",
    "                    'DQA1*05:09', 'DQA1*04:02', 'DQA1*04:04', 'DQA1*06:01', 'DQA1*06:02', \\\n",
    "                    'DQA1*02:01', 'DQA1*04:01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct a pseudo sequence dictionary from full sequence data\n",
    "\n",
    "# DRA_seq_unique\n",
    "\n",
    "\n",
    "HLA_II_alpha_pseudo_rec_dict = defaultdict(str)\n",
    "\n",
    "\n",
    "adjust_pos_alpha = [pos for pos in fifteen]\n",
    "adjust_pos_alpha[0] = adjust_pos_alpha[0] - 1\n",
    "\n",
    "def get_a_half_modify_15(lookup_dict, allele, adjust_pos_alpha, modify_flag):\n",
    "    seq_candids = list(lookup_dict[allele])\n",
    "    if modify_flag:\n",
    "        modify_adjust_pos_alpha = [pos for pos in adjust_pos_alpha]\n",
    "        modify_adjust_pos_alpha[5] = 53\n",
    "        seq_pseudos_modify = list(set([\"\".join([item[ind-4] for ind in modify_adjust_pos_alpha]) for item in seq_candids]))\n",
    "        seq_pseudos = [item[:6] + 'X' + item[7:] for item in seq_pseudos_modify]   \n",
    "    else:\n",
    "        seq_pseudos = list(set([\"\".join([item[ind-4] for ind in adjust_pos_alpha]) for item in seq_candids]))\n",
    "    seq_pseudo_noX = [seq for seq in seq_pseudos if seq[0]!= 'X']\n",
    "    if len(seq_pseudo_noX) == 1:\n",
    "        return True, seq_pseudo_noX[0]\n",
    "    else:\n",
    "        return False, \"\"\n",
    "    \n",
    "    \n",
    "for item in list_HLA_II_alpha:\n",
    "    if item[:3] == \"DQA\":\n",
    "        modify_flag = (item in extra_modify_DQAs)\n",
    "        sub_flag, seq = get_a_half_modify_15(DQA1_seq_dict, item, adjust_pos_alpha, modify_flag)\n",
    "        if not sub_flag:\n",
    "            print(\"seq_pseudo_noX len is not 1\")\n",
    "            print(\"item = \", item)\n",
    "            break\n",
    "        HLA_II_alpha_pseudo_rec_dict[item] = seq     \n",
    "    elif item[:3] == \"DPA\":\n",
    "        sub_flag, seq = get_a_half_modify_15(DPA1_seq_dict, item, adjust_pos_alpha, False)\n",
    "        if not sub_flag:\n",
    "            print(\"seq_pseudo_noX len is not 1\")\n",
    "            print(\"item = \", item)\n",
    "            break\n",
    "        HLA_II_alpha_pseudo_rec_dict[item] = seq     \n",
    "    elif item[:8] == \"DRA\":\n",
    "        seq = 'QEFFIASGAAVDAIM'\n",
    "        HLA_II_alpha_pseudo_rec_dict[item] = seq \n",
    "    else:\n",
    "        print(\"error found, first three letters exception\")\n",
    "        print(item)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now it is verified that this way of doing the adjustment gets pseudo sequences\n",
    "# same as that from file \"../../data/intermediate_data/pseudosequence_2016_all_X.dat\"\n",
    "HLA_II_alpha_pseudo_rec_dict == HLA_II_alpha_pseudo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([DRA_seq_unique[ind-4] for ind in adjust_pos_alpha]) == 'QEFFIASGAAVDAIM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_pos_alpha = [pos for pos in fifteen]\n",
    "adjust_pos_alpha[0] = adjust_pos_alpha[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DPA1*01:03',\n",
       " 'DPA1*02:01',\n",
       " 'DPA1*02:02',\n",
       " 'DQA1*01:01',\n",
       " 'DQA1*01:02',\n",
       " 'DQA1*01:03',\n",
       " 'DQA1*01:04',\n",
       " 'DQA1*01:05',\n",
       " 'DQA1*02:01',\n",
       " 'DQA1*03:01',\n",
       " 'DQA1*03:02',\n",
       " 'DQA1*03:03',\n",
       " 'DQA1*04:01',\n",
       " 'DQA1*05:01',\n",
       " 'DQA1*05:05',\n",
       " 'DQA1*06:01',\n",
       " 'DRA']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_HLA_II_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 11, 22, 24, 31, 52, 53, 58, 59, 61, 65, 66, 68, 72, 73]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifteen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HVIIQ-AEFYLNPDQSGEFMFDFDGDEIFHVDMAKKETVWRLEEFGRFASFEAQGALANIAVDKANLEIMTKRSN'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all DRA and DPA sequences have a deletion at position 5\n",
    "DRA_seq_unique\n",
    "# DRA sequence is perfectly fine with just -4 & move the first to the one next \n",
    "# to it on the left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### below is a summary of the adjustments need to make\n",
    "\n",
    "(0) In general, the 15 positions \n",
    "9, 11, 22, 24, 31, 52, 53, 58, 59, 61, 65, 66, 68, 72, 73\n",
    "given in NetMHCIIpan-3.0 for HLA-II alpha chains need to be subtracted by 4 in order to match the info given in full sequences files:\n",
    "\n",
    "    DRA_prot.alfas\n",
    "    DPA_prot.alfas\n",
    "    DQA_prot.alfas\n",
    "\n",
    "(1) On top of that, the first one (pos 9) of these 15 positions needs to be subtracted by an additional 1 (one guess is it is related to a deletion in 0-indexed position 5, for example, as in the unique full sequence 'HVIIQ-AEFYLNPDQSGEFMFDFDGDEIFHVDMAKKETVWRLEEFGRFASFEAQGALANIAVDKANLEIMTKRSN' for DRA alleles, and the alignment in NetMHCIIpan-3.0 might have ignored this deletion and caused the relative distance between the first postion and the second to be shorter by 1).\n",
    "\n",
    "(2) Besides these, there is an additional modification needed to be done if the alpha chains falls into a set of DQAs:\n",
    "\n",
    "'DQA1*05:04','DQA1*05:07', 'DQA1*05:01', 'DQA1*05:06', 'DQA1*05:03', 'DQA1*05:02', 'DQA1*05:08', 'DQA1*05:05', 'DQA1*05:11', 'DQA1*05:10', 'DQA1*05:09', 'DQA1*04:02', 'DQA1*04:04', 'DQA1*06:01', 'DQA1*06:02', 'DQA1*02:01', 'DQA1*04:01'\n",
    "\n",
    "Most of these DQAs are got from Fig.2 of NetMHCIIpan-3.0 paper, except that 'DQA1*04:01' was not mentioned in the paper but found out to have the same behavior in terms of adjusting positions for pseudo sequence matching, and so it is added into this list. Based on the paper, the sequences of these HLA-II alpha chains have a deletion on position 53 (under indexing system in NetMHCIIpan-3.0 paper). However, the full sequences from DQA_prot.alfas show no deletion here but a deletion on position 48 (under indexing system in NetMHCIIpan-3.0 paper).\n",
    "For example, DQA1_05_04 has sequence (starting from position 35)\n",
    "\n",
    "DLGRKETVWCLPVLRQFR-FDPQFALTNIAVLKHNLN...\n",
    "\n",
    "v.s.\n",
    "\n",
    "DLGRKETVWCLPV-LRQFRFDPQFALTNIAVLKHNLN...\n",
    "\n",
    "given by full sequene info as in \n",
    "\n",
    "    DQA_prot.alfas.\n",
    "\n",
    "Thus, the deletion at postion 48 is not considered by the alignment of NetMHCIIpan-3.0 as a deletion, but the one at position 53 is. So in order to construct pseudo sequence in the same way as in \n",
    "\n",
    "    pseudosequence_2016_all_X.dat\n",
    "for these special DQAs, one additional adjustment we need to make is that, to amino acids for positions 48, 49, 50, 51, 52, we need to take those on positions 49, 50, 51, 52, 53 (under indexing system of NetMHCIIpan-3.0) from the full sequences in \n",
    "\n",
    "    DQA_prot.alfas \n",
    "instead, and if we need to get amino acid on position 53, write an \"X\" instead. For other DQAs that do not fall into this special set, DPAs and the DRA, this adjustment should not be done.\n",
    "\n",
    "(3) If one HLA-II A allele has multiple corresponding pseudo sequences, then ignore those sequences starting with \"X\" and only keep the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# the content in this cell was the reasoning when trying to figure out the adjustments needed for alignments. \n",
    "# the markdown cell above is a neater summary\n",
    "# -----------------------------------\n",
    "\n",
    "\n",
    "# If we use the current full sequence of DRA as base line for the alignment,  \n",
    "\n",
    "# on one hand, \n",
    "# the relative distance between the positions from NetMHC-II-pan-3.0 seems to \n",
    "# be ignoring the deletion at position 5 (0-indexed), and then adding 5 to the indexes of all positions\n",
    "\n",
    "# on the other hand, \n",
    "# since all other positions match perfectly after shifting by -4 except 52 & 53 when DQA has delection \n",
    "# on position 53 according to alignment in NetMHC-II-pan-3.0 \n",
    "# but on position 48(44 under 0-indexed, 44+4 = 48) according to \"../data/HLA_TCR_contact/DQA1_prot.alfas\"\n",
    "# the pseudo sequences from NetMHC-II-pan-3.0 write 'X' for position 53 and use the aa on position 53 \n",
    "# instead of that on position 52.\n",
    "# In this sense, comparied to DQA1_prot.alfas, NetMHC-II-pan-3.0 igores the deletion at position 48\n",
    "# and push all aas from postion 49 to 53 to the left by one position, and use 'X' for position 53\n",
    "\n",
    "# Thus, if DQA falls into those needing additional modifications, \n",
    "# compared with the alignment in NetMHC-II-pan-3.0, the sequences in DQA1_prot.alfas ignores the deletion\n",
    "# on position 53, considers pos 48 as a delection and pushed aas on pos 48 to 52 to the right by one pos\n",
    "# and uses '-' for position 48\n",
    "\n",
    "# If DQA needs additional modifcation, for getting aas for the additional positions, \n",
    "# 49, 50 & 51 (45, 46 & 47 under 0-indexing) need to be changed to 50, 51 & 52\n",
    "# But, if DQA does not fall into those needing additional modifications, \n",
    "# it is fine to just use the same processing as on DRA sequence.\n",
    "\n",
    "\n",
    "# since from the original 15 positions given by NetMHC-II-pan-3.0, \n",
    "# we need to modify the first position index by subtracting by 1,\n",
    "# and this will change the original 9 to 8. \n",
    "# As a result, we can ignore the first position index 8 \n",
    "# (4 under 0-indexing) in the 18 additional one\n",
    "\n",
    "\n",
    "# for other positions except the first one in the original 15 positions \n",
    "# there does not seem to be a problem\n",
    "# one guess is it is due to the deletion on position 5(0-indexed in DRA_seq_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DQA1_seq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 additional positions (index adjusted) for HLA-II alpha chain:\n",
    "eighteen = [4, 28, 35, 39, 45, 46, 47, 50, 51, 53, 56, 58, 60, 63, 65, 67, 71, 72]\n",
    "# add 4 to all to take them on the same scale as the original fifteen\n",
    "up_eighteen = [ind + 4 for ind in eighteen]\n",
    "# ignore the first pos 8 (4 under 0-indexing, since it is the same as the first position\n",
    "# in original fifteen 9 moved 1 position to the left\n",
    "up_seventeen = up_eighteen[1:]\n",
    "up_seventeen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's check whether for each HLA-II alpha chain, we can find a unique pseudo \n",
    "# sequence for it based on these 17 positions\n",
    "\n",
    "\n",
    "flag_HLA_II_on_17 = []\n",
    "HLA_II_alpha_pseudo_17_dict = defaultdict(str)\n",
    "\n",
    "\n",
    "adjust_pos_up_17 = [pos for pos in up_seventeen]\n",
    "\n",
    "def get_a_half_modify_17(lookup_dict, allele, adjust_pos_up_17, modify_flag):\n",
    "    seq_candids = list(lookup_dict[allele])\n",
    "    if modify_flag:\n",
    "        modify_adjust_pos_up_17 = [pos for pos in adjust_pos_up_17]\n",
    "        modify_adjust_pos_up_17[3:6] = [pos+1 for pos in adjust_pos_up_17[3:6]]\n",
    "        seq_pseudos = list(set([\"\".join([item[ind-4] for ind in modify_adjust_pos_up_17]) for item in seq_candids])) \n",
    "    else:\n",
    "        seq_pseudos = list(set([\"\".join([item[ind-4] for ind in adjust_pos_up_17]) for item in seq_candids]))\n",
    "    seq_pseudo_noX = [seq for seq in seq_pseudos if seq[0]!= 'X']\n",
    "    if len(seq_pseudo_noX) == 1:\n",
    "        return True, seq_pseudo_noX[0]\n",
    "    else:\n",
    "        return False, \"\"\n",
    "    \n",
    "    \n",
    "for item in list_HLA_II_alpha:\n",
    "    if item[:3] == \"DQA\":\n",
    "        modify_flag = (item in extra_modify_DQAs)\n",
    "        sub_flag, seq = get_a_half_modify_17(DQA1_seq_dict, item, adjust_pos_up_17, modify_flag)\n",
    "        flag_HLA_II_on_17 += [sub_flag]\n",
    "        if not sub_flag:\n",
    "            print(\"seq_pseudo_noX len is not 1\")\n",
    "            print(\"item = \", item)\n",
    "            break\n",
    "        HLA_II_alpha_pseudo_17_dict[item] = seq     \n",
    "    elif item[:3] == \"DPA\":\n",
    "        sub_flag, seq = get_a_half_modify_17(DPA1_seq_dict, item, adjust_pos_up_17, False)\n",
    "        flag_HLA_II_on_17 += [sub_flag]\n",
    "        if not sub_flag:\n",
    "            print(\"seq_pseudo_noX len is not 1\")\n",
    "            print(\"item = \", item)\n",
    "            break\n",
    "        HLA_II_alpha_pseudo_17_dict[item] = seq     \n",
    "    elif item[:3] == \"DRA\":\n",
    "        flag_HLA_II_on_17 += [True]\n",
    "        seq = \"\".join([DRA_seq_unique[ind-4] for ind in adjust_pos_up_17])\n",
    "        HLA_II_alpha_pseudo_17_dict[item] = seq \n",
    "    else:\n",
    "        print(\"error found, first three letters exception\")\n",
    "        print(item)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(flag_HLA_II_on_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[len(value) for value in HLA_II_alpha_pseudo_17_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 4, 3, 3, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we look into how many out of the 17 positions have diversity in terms of amino acids\n",
    "# among the 17 different HLA-II alpha chains\n",
    "\n",
    "nunique_17 = []\n",
    "\n",
    "for i in range(17):\n",
    "    cur_aas = ''\n",
    "    for value in list(HLA_II_alpha_pseudo_17_dict.values()):\n",
    "        cur_aas += value[i]\n",
    "    nunique_17 += [len(set(cur_aas))]\n",
    "\n",
    "nunique_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49, 50, 51, 55, 67, 71, 75]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7 out of 17 positions have diverity\n",
    "add_HLA_II_7 = [up_seventeen[i] for i in range(17) if nunique_17[i] > 1]\n",
    "add_HLA_II_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the 7 additional positions with the original 15 to make a set of 22 positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_pos_alpha = [pos for pos in fifteen]\n",
    "# note that the adjustification on the first index is already done here\n",
    "adjust_pos_alpha[0] = adjust_pos_alpha[0] - 1\n",
    "extended_HLA_II_alpha = adjust_pos_alpha + add_HLA_II_7\n",
    "extended_HLA_II_alpha.sort()\n",
    "#extended_HLA_II_alpha\n",
    "# [8,11,22,24,31,49,50,51,52,53,55,58,59,61,65,66,67,68,71,72,73,75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now move on to get pseudo sequences based on these 22 positions:\n",
    "\n",
    "flag_HLA_II_on_22 = []\n",
    "HLA_II_alpha_pseudo_22_dict = defaultdict(str)\n",
    "\n",
    "\n",
    "adjust_pos_up_22 = [pos for pos in extended_HLA_II_alpha]\n",
    "\n",
    "def get_a_half_modify_22(lookup_dict, allele, adjust_pos_up_22, modify_flag):\n",
    "    seq_candids = list(lookup_dict[allele])\n",
    "    if modify_flag:\n",
    "        modify_adjust_pos_up_22 = [pos+1 if pos in [49,50,51,52] else pos for pos in adjust_pos_up_22]\n",
    "        seq_pseudos_modify = list(set([\"\".join([item[ind-4] for ind in modify_adjust_pos_up_22]) for item in seq_candids])) \n",
    "        seq_pseudos = [item[:9] + 'X' + item[10:] for item in seq_pseudos_modify]   \n",
    "    else:\n",
    "        seq_pseudos = list(set([\"\".join([item[ind-4] for ind in adjust_pos_up_22]) for item in seq_candids]))\n",
    "    seq_pseudo_noX = [seq for seq in seq_pseudos if seq[0]!= 'X']\n",
    "    if len(seq_pseudo_noX) == 1:\n",
    "        return True, seq_pseudo_noX[0]\n",
    "    else:\n",
    "        return False, \"\"\n",
    "    \n",
    "    \n",
    "for item in list_HLA_II_alpha:\n",
    "    if item[:3] == \"DQA\":\n",
    "        modify_flag = (item in extra_modify_DQAs)\n",
    "        sub_flag, seq = get_a_half_modify_22(DQA1_seq_dict, item, adjust_pos_up_22, modify_flag)\n",
    "        flag_HLA_II_on_22 += [sub_flag]\n",
    "        if not sub_flag:\n",
    "            print(\"seq_pseudo_noX len is not 1\")\n",
    "            print(\"item = \", item)\n",
    "            break\n",
    "        HLA_II_alpha_pseudo_22_dict[item] = seq     \n",
    "    elif item[:3] == \"DPA\":\n",
    "        sub_flag, seq = get_a_half_modify_22(DPA1_seq_dict, item, adjust_pos_up_22, False)\n",
    "        flag_HLA_II_on_22 += [sub_flag]\n",
    "        if not sub_flag:\n",
    "            print(\"seq_pseudo_noX len is not 1\")\n",
    "            print(\"item = \", item)\n",
    "            break\n",
    "        HLA_II_alpha_pseudo_22_dict[item] = seq     \n",
    "    elif item[:8] == \"DRA\":\n",
    "        flag_HLA_II_on_22 += [True]\n",
    "        seq = \"\".join([DRA_seq_unique[ind-4] for ind in adjust_pos_up_22])\n",
    "        HLA_II_alpha_pseudo_22_dict[item] = seq \n",
    "    else:\n",
    "        print(\"error found, first three letters exception\")\n",
    "        print(item)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(flag_HLA_II_on_22)/len(flag_HLA_II_on_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str,\n",
       "            {'DPA1*01:03': 'YAFFMGQAFSEGGAILNNNTLQ',\n",
       "             'DPA1*02:01': 'YAFFQGRAFSEGGAILNNNTLQ',\n",
       "             'DPA1*02:02': 'YMFFQGRAFSEGGAILNNNTLQ',\n",
       "             'DQA1*01:01': 'CNYHESKFGGDGARVAKHNIMK',\n",
       "             'DQA1*01:02': 'CNYHQSKFGGDGARVAKHNIMK',\n",
       "             'DQA1*01:03': 'CNFHQSKFGGDGARVAKHNIMK',\n",
       "             'DQA1*01:04': 'CNYHESKFGGDGARVAKHNIMK',\n",
       "             'DQA1*01:05': 'CNYHESKFGGDGARVAKHNIMK',\n",
       "             'DQA1*02:01': 'YNFHEHRLRXDFATVLKHNILK',\n",
       "             'DQA1*03:01': 'YNYHERRFRRDFATVLKHNIVK',\n",
       "             'DQA1*03:02': 'YNYHERRFRRDFATVLKHNIVK',\n",
       "             'DQA1*03:03': 'YNYHERRFRRDFATVLKHNIVK',\n",
       "             'DQA1*04:01': 'YNYHQRQFRXDFATVTKHNILK',\n",
       "             'DQA1*05:01': 'YNYHQRQFRXDFATVLKHNSLK',\n",
       "             'DQA1*05:05': 'YNYHQRQFRXDFATVLKHNSLK',\n",
       "             'DQA1*06:01': 'YNFHQRQFRXDFATVTKHNILK',\n",
       "             'DRA': 'QEFFIGRFASEGAAVDKAEIMK'})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLA_II_alpha_pseudo_22_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "HLA_II_alpha_pseudo_22_value = [HLA_II_alpha_pseudo_22_dict[key] for key in list_HLA_II_alpha]\n",
    "\n",
    "df_HLA_II_alpha_22 = pd.DataFrame(list(zip(list_HLA_II_alpha, HLA_II_alpha_pseudo_22_value)), \\\n",
    "                                 columns = [\"allele\", \"seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dictionary out in the format of a table\n",
    "df_HLA_II_alpha_22.to_csv(\"../../data/intermediate_data/t4_HLA_II_v2_alpha_pseudo_22_dict.csv\", \n",
    "                          index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go and check a few HLA-II alpha chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str,\n",
       "            {'DPA1*01:03': 'YAFFMFSGGAILNTL',\n",
       "             'DPA1*02:01': 'YAFFQFSGGAILNTL',\n",
       "             'DPA1*02:02': 'YMFFQFSGGAILNTL',\n",
       "             'DQA1*01:01': 'CNYHEGGGARVAHIM',\n",
       "             'DQA1*01:02': 'CNYHQGGGARVAHIM',\n",
       "             'DQA1*01:03': 'CNFHQGGGARVAHIM',\n",
       "             'DQA1*01:04': 'CNYHEGGGARVAHIM',\n",
       "             'DQA1*01:05': 'CNYHEGGGARVAHIM',\n",
       "             'DQA1*02:01': 'YNFHERXFATVLHIL',\n",
       "             'DQA1*03:01': 'YNYHERRFATVLHIV',\n",
       "             'DQA1*03:02': 'YNYHERRFATVLHIV',\n",
       "             'DQA1*03:03': 'YNYHERRFATVLHIV',\n",
       "             'DQA1*04:01': 'YNYHQRXFATVTHIL',\n",
       "             'DQA1*05:01': 'YNYHQRXFATVLHSL',\n",
       "             'DQA1*05:05': 'YNYHQRXFATVLHSL',\n",
       "             'DQA1*06:01': 'YNFHQRXFATVTHIL',\n",
       "             'DRA': 'QEFFIASGAAVDAIM'})"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLA_II_alpha_pseudo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'DRA'\n",
    "''.join(['QEFFIGRFASEGAAVDKAEIMK'[i] for i in range(22) if adjust_pos_up_22[i] in fifteen]) == 'EFFIASGAAVDAIM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'DPA1*01:03'\n",
    "''.join(['YAFFMGQAFSEGGAILNNNTLQ'[i] for i in range(22) if adjust_pos_up_22[i] in fifteen]) == 'AFFMFSGGAILNTL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'DQA1*01:01'\n",
    "''.join(['CNYHESKFGGDGARVAKHNIMK'[i] for i in range(22) if adjust_pos_up_22[i] in fifteen]) == 'NYHEGGGARVAHIM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'DQA1*05:01'\n",
    "''.join(['YNYHQRQFRXDFATVLKHNSLK'[i] for i in range(22) if adjust_pos_up_22[i] in fifteen]) == 'NYHQRXFATVLHSL'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
