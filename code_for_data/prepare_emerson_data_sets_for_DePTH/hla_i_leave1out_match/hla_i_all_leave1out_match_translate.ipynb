{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/\"\n",
    "\n",
    "old_folder = \"intermediate_data/hla_i_leave1out_match_raw_v/\"\n",
    "new_folder = \"HLA_I_leave1out_match/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(data_dir + old_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the translate file to make translate dict\n",
    "\n",
    "df_v_allele_trans = \\\n",
    "pd.read_csv(data_dir + \"intermediate_data/v_allele_translate_table_fillin.csv\", header=0)\n",
    "\n",
    "df_v_allele_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_allele_trans_dict = defaultdict(str)\n",
    "for v_allele, translate in \\\n",
    "        zip(df_v_allele_trans.v_allele_new.tolist(),\n",
    "            df_v_allele_trans.v_allele_translate.tolist()):\n",
    "    v_allele_trans_dict[v_allele] = translate\n",
    "\n",
    "len(v_allele_trans_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRBV1*01',\n",
       " 'TRBV2*01',\n",
       " 'TRBV3-1*01',\n",
       " 'TRBV3-2*01',\n",
       " 'TRBV3-2*02',\n",
       " 'TRBV4-1*01',\n",
       " 'TRBV4-2*01',\n",
       " 'TRBV4-3*01',\n",
       " 'TRBV5-1*01',\n",
       " 'not_found',\n",
       " 'TRBV5-3*01',\n",
       " 'TRBV5-4*01',\n",
       " 'TRBV5-5*01',\n",
       " 'TRBV5-6*01',\n",
       " 'TRBV5-7*01',\n",
       " 'TRBV5-8*01',\n",
       " 'TRBV6-1*01',\n",
       " 'TRBV6-4*01',\n",
       " 'TRBV6-5*01',\n",
       " 'TRBV6-6*01',\n",
       " 'TRBV6-7*01',\n",
       " 'TRBV6-8*01',\n",
       " 'TRBV6-9*01',\n",
       " 'TRBV7-1*01',\n",
       " 'TRBV7-2*01',\n",
       " 'TRBV7-3*01',\n",
       " 'TRBV7-3*02',\n",
       " 'TRBV7-3*03',\n",
       " 'TRBV7-4*01',\n",
       " 'not_found',\n",
       " 'not_found',\n",
       " 'TRBV7-6*01',\n",
       " 'TRBV7-7*01',\n",
       " 'TRBV7-8*01',\n",
       " 'TRBV7-8*02',\n",
       " 'TRBV7-9*01',\n",
       " 'not_found',\n",
       " 'TRBV9*01',\n",
       " 'TRBV10-1*01',\n",
       " 'TRBV10-2*01',\n",
       " 'TRBV10-3*01',\n",
       " 'TRBV11-1*01',\n",
       " 'TRBV11-2*02',\n",
       " 'TRBV11-3*01',\n",
       " 'TRBV12-1*01',\n",
       " 'TRBV12-2*01',\n",
       " 'TRBV12-5*01',\n",
       " 'TRBV13*01',\n",
       " 'TRBV14*01',\n",
       " 'TRBV15*01',\n",
       " 'TRBV16*01',\n",
       " 'TRBV17*01',\n",
       " 'TRBV18*01',\n",
       " 'TRBV19*01',\n",
       " 'TRBV20-1*01',\n",
       " 'TRBV21-1*01',\n",
       " 'TRBV23-1*01',\n",
       " 'TRBV25-1*01',\n",
       " 'TRBV26*01',\n",
       " 'TRBV27*01',\n",
       " 'TRBV28*01',\n",
       " 'TRBV29-1*01',\n",
       " 'TRBV30*01',\n",
       " 'TRBV30*02',\n",
       " 'not_found']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(v_allele_trans_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_dir+new_folder+\"HLA_I_leave1out_match_B0801/test\")\n",
    "os.makedirs(data_dir+new_folder+\"HLA_I_leave1out_match_B0801/train_valid\")\n",
    "\n",
    "os.makedirs(data_dir+new_folder+\"HLA_I_leave1out_match_B0702/test\")\n",
    "os.makedirs(data_dir+new_folder+\"HLA_I_leave1out_match_B0702/train_valid\")\n",
    "\n",
    "os.makedirs(data_dir+new_folder+\"HLA_I_leave1out_match_C0701/test\")\n",
    "os.makedirs(data_dir+new_folder+\"HLA_I_leave1out_match_C0701/train_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict = defaultdict(str)\n",
    "\n",
    "index_dict[\"1\"] = \"B0801\"\n",
    "index_dict[\"11\"] = \"B0702\"\n",
    "index_dict[\"23\"] = \"C0701\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_file in file_names:\n",
    "    \n",
    "    cur_df = pd.read_csv(data_dir + old_folder + cur_file, header=0)\n",
    "    \n",
    "    cur_tcr_old = cur_df.tcr.tolist()\n",
    "    cur_hla = cur_df.hla_allele.tolist()\n",
    "    \n",
    "    cur_tcr_new = [\",\".join([v_allele_trans_dict[x.split(\",\")[0]], x.split(\",\")[1]]) for x in cur_tcr_old]\n",
    "    \n",
    "    trans_df = pd.DataFrame(list(zip(cur_tcr_new, cur_hla)), columns = [\"tcr\", \"hla_allele\"])\n",
    "    \n",
    "    new_filename = \"_\".join(cur_file.split(\"_\")[(-3):(-1)])\n",
    "    \n",
    "    subfolder_name = \"HLA_I_leave1out_match_\"+index_dict[cur_file.split(\".\")[0].split(\"_\")[-1]]\n",
    "    \n",
    "    if cur_file.split(\"_\")[-3] == \"test\":\n",
    "        trans_df.to_csv(data_dir+new_folder+ subfolder_name+\"/test/\" + new_filename, \n",
    "                        index = False)\n",
    "    else:\n",
    "        trans_df.to_csv(data_dir+new_folder+ subfolder_name+\"/train_valid/\" + new_filename, \n",
    "                        index = False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 2)\n",
      "(20025, 2)\n",
      "(530, 2)\n",
      "(1394, 2)\n",
      "(3704, 2)\n",
      "(1234, 2)\n",
      "(6970, 2)\n",
      "(4005, 2)\n",
      "(2650, 2)\n",
      "(2490, 2)\n",
      "(4182, 2)\n",
      "(4390, 2)\n",
      "(18520, 2)\n",
      "(6675, 2)\n",
      "(1335, 2)\n",
      "(6170, 2)\n",
      "(498, 2)\n",
      "(20910, 2)\n"
     ]
    }
   ],
   "source": [
    "# combine all data files together\n",
    "# to (1)verify whether all translated v alleles belong to those in combo_xcr.tsv\n",
    "# (2)get the maximum length of CDR3s involved\n",
    "\n",
    "all_tcrs = []\n",
    "all_hlas = []\n",
    "\n",
    "for cur_file in file_names:\n",
    "\n",
    "    new_filename = \"_\".join(cur_file.split(\"_\")[(-3):(-1)])\n",
    "    \n",
    "    subfolder_name = \"HLA_I_leave1out_match_\"+index_dict[cur_file.split(\".\")[0].split(\"_\")[-1]]\n",
    "    \n",
    "    if cur_file.split(\"_\")[-3] == \"test\":\n",
    "        cur_df = pd.read_csv(data_dir+new_folder+ subfolder_name+\"/test/\" + new_filename, \n",
    "                             header=0)\n",
    "    else:\n",
    "        cur_df = pd.read_csv(data_dir+new_folder+ subfolder_name+\"/train_valid/\" + new_filename, \n",
    "                             header=0)        \n",
    "        \n",
    "    print(cur_df.shape)\n",
    "\n",
    "    all_tcrs = all_tcrs + cur_df.tcr.tolist()\n",
    "    all_hlas = all_hlas + cur_df.hla_allele.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([x.split(\",\")[0] for x in all_tcrs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 2)\n",
      "(20025, 2)\n",
      "(530, 2)\n",
      "(1394, 2)\n",
      "(3704, 2)\n",
      "(1234, 2)\n",
      "(6970, 2)\n",
      "(4005, 2)\n",
      "(2650, 2)\n",
      "(2490, 2)\n",
      "(4182, 2)\n",
      "(4390, 2)\n",
      "(18520, 2)\n",
      "(6675, 2)\n",
      "(1335, 2)\n",
      "(6170, 2)\n",
      "(498, 2)\n",
      "(20910, 2)\n"
     ]
    }
   ],
   "source": [
    "# verify the overlap between old v alleles and those corresponding to not_found\n",
    "# after translation\n",
    "\n",
    "all_tcrs_old = []\n",
    "\n",
    "for cur_file in file_names:\n",
    "    \n",
    "    cur_df = pd.read_csv(data_dir + old_folder + cur_file, header = 0)\n",
    "    print(cur_df.shape)\n",
    "    all_tcrs_old = all_tcrs_old + cur_df.tcr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tcr_set = set([x.split(\",\")[0] for x in all_tcrs_old])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TCRBV05-02*01',\n",
       " 'TCRBV07-05*01',\n",
       " 'TCRBV07-05*02',\n",
       " 'TCRBV08-02*01',\n",
       " 'TCRBVA-or09_02*01'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_set = set([v for v, trans in zip(df_v_allele_trans.v_allele_new.tolist(),\n",
    "                                           df_v_allele_trans.v_allele_translate.tolist()) if trans == \"not_found\"])\n",
    "\n",
    "not_found_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indeed, there is no old format v gene allele translated into not_found\n",
    "# among those used in train/validation/test under all_match setting\n",
    "len(old_tcr_set.intersection(not_found_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look into the range of CDR3 length\n",
    "\n",
    "set([len(x.split(\",\")[1]) for x in all_tcrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
